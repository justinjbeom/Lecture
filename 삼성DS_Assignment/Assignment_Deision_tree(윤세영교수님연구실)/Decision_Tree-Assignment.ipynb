{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Tree Based Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataset(filename):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    print(df.head(10))\n",
    "    input_features=['Age','Income','Limit','Cards','Student','Education']\n",
    "    target_feature=['Balance']\n",
    "    df_input=df[input_features+target_feature]\n",
    "    df_input['Student'].replace('Yes',1,inplace=True)\n",
    "    df_input['Student'].replace('No',0,inplace=True)\n",
    "    \n",
    "    train=df_input.sample(frac=0.75,random_state=3) #split into train and test\n",
    "    test=df_input.drop(train.index)\n",
    "    trainingSet=train.values\n",
    "    testSet=test.values\n",
    "    return trainingSet, testSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RSS(splits):\n",
    "    residual = 0\n",
    "    for split in splits:\n",
    "        if(len(split) != 0):\n",
    "            mean = np.mean([element[-1] for element in split]) #TODO\n",
    "            residual = residual+ np.sum([ (element[-1] - mean)**2 for element in split]) #TODO\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_1 = np.array([[[1,2,0,2],[2,4,0,8]],[[1,3,4,5]]])\n",
    "RSS_value = RSS(split_1)\n",
    "if (type(RSS_value) not in [int,float,np.float16,np.float32,np.float64]):\n",
    "    print(\"TypeError : check your output\")\n",
    "elif(RSS(split_1) == 18.0):\n",
    "    print(\"Your calculations are right, at least on this specific example\")\n",
    "else:\n",
    "    print(\"Your calculations are wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(index, value, data):  #data has a form like np.array([[1,2,0,2],[2,4,0,8]]), last element is a target value.\n",
    "    left_split = [element for element in data if(element[index]<value)] #TODO condition\n",
    "    right_split = [element for element in data if(element[index]>=value)] #TODO condition\n",
    "    return [left_split, right_split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "def split_tester(data): #find optimal split\n",
    "    optimal_split_ind, optimal_split_value, optimal_residual, optimal_splits = -1,-1,float(\"inf\"),[] #initialization.\n",
    "    for curr_ind in range(data.shape[1]-1): #for all features , Age, Income, Limit....\n",
    "        min_val=np.min(data[:,curr_ind])\n",
    "        for curr_val in data: #for all values in a feature of the data.\n",
    "            if curr_val[curr_ind] == min_val:\n",
    "                continue\n",
    "            if(verbose):print(\"Curr_split : \" + str((curr_ind, curr_val[curr_ind])))\n",
    "            split_result = split(curr_ind, curr_val[curr_ind], data) \n",
    "                        \n",
    "            if(verbose):print(split_result)\n",
    "            residual_value = RSS(split_result)\n",
    "            \n",
    "            if(verbose):print(\"Residual : \" + str(residual_value))\n",
    "            if residual_value < optimal_residual:\n",
    "                optimal_split_ind, optimal_split_value, optimal_residual, optimal_splits = curr_ind,\\\n",
    "                                                                    curr_val[curr_ind], residual_value, split_result\n",
    "                \n",
    "    return optimal_split_ind, optimal_split_value, optimal_splits   # index is feature, value is for crietria, splits is data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_ind, optimal_value,_ = split_tester(np.array([[0,-10],[2,4],[4,5]]))\n",
    "if (optimal_ind != 0):\n",
    "    print(\"Your optimal split index is wrong (Careful, Python arrays starts at 0)\")\n",
    "elif(optimal_value != 2):\n",
    "    print(\"Your optimal split value is wrong\")\n",
    "else:\n",
    "    print(\"You found the good split index and value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_building(data, min_size): #minimun data size in a split\n",
    "    if(data.shape[0] > min_size): #building tree until the minimum.\n",
    "        ind, value, [left, right] = split_tester(data) #get optimal criteria using split_tester\n",
    "        left, right = np.array(left), np.array(right)\n",
    "        return [tree_building(left, min_size), tree_building(right, min_size),ind,value]\n",
    "    else:\n",
    "        return data  #output is the data in a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(tree, input_vector):#recursive until reaching the leaf node.\n",
    "    if(type(tree[-1]) != np.float64): #when reach the leaf node. tree represent the split data.\n",
    "        if(len(tree) == 1):  #when number of data is 1\n",
    "            return(tree[0][-1])   #get the wage in the data\n",
    "        else:\n",
    "            return(np.mean([element[-1] for element in tree]))   #average of a leaf node.\n",
    "    else:  #before reaching leaf node\n",
    "        left_tree, right_tree, split_ind, split_value = tree #information of the current split \n",
    "        if(input_vector[split_ind]<split_value): #which split the input data belong to\n",
    "            return predict(left_tree, input_vector)\n",
    "        else:\n",
    "            return predict(right_tree, input_vector)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getError(testSet, predictions):\n",
    "    difference=np.sqrt(np.average((np.array(testSet)[:,-1]-np.array(predictions))**2))\n",
    "    print('test plot')\n",
    "    plt.plot(np.array(testSet)[:,-1], np.array(predictions),  'ro', label='test set')\n",
    "    plt.plot(np.array(testSet)[:,-1], np.array(testSet)[:,-1], label='standard line')\n",
    "    plt.xlabel(\"Target\")\n",
    "    plt.ylabel(\"Output\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return difference\n",
    "\n",
    "\n",
    "# def Decision_Tree():\n",
    "#     training_set,test_set=loadDataset('Credit.csv')\n",
    "#     tree = tree_building(training_set,10)\n",
    "#     predictions=[]\n",
    "#     for employee in test_set:\n",
    "#         predictions.append(predict(tree,employee))\n",
    "#     error = getError(test_set, predictions)\n",
    "#     print('Error(RMSE): ' + repr(error))\n",
    "    \n",
    "# Decision_Tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Subsample(dataset, ratio): #function of samping for  bootstrap\n",
    "    sample = list()\n",
    "    n_sample = round(dataset.shape[0] * ratio) #size of each boostrap\n",
    "    while len(sample) < n_sample: #loop for sampling with replacement\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index,:])\n",
    "    return np.array(sample) #return a sampled bootstrap\n",
    "\n",
    "def Bagging(repeat,ratio):\n",
    "    training_set,test_set=loadDataset('Credit.csv')\n",
    "    predictions=[]\n",
    "    random.seed(3)\n",
    "    for i in range(repeat):\n",
    "        pred_temp=[] #list for prediction of each model\n",
    "        train_subset=Subsample(training_set,ratio) #using a boostrap for training set.\n",
    "        \n",
    "        tree =  ####fill out here ### use 'tree_building' function for making a decision tree model using train_subset with min_size=10.\n",
    "        \n",
    "        for employee in test_set: #loop for each test data\n",
    "            \n",
    "            pred_temp.append(          )####fill out here ##### we need to use 'predict' function to get a prediction of each test data \n",
    "            \n",
    "        predictions.append(pred_temp) #append prediction of each model\n",
    "        \n",
    "    predictions_avg=  ####fill out here ##### get an average predictions of models\n",
    "    \n",
    "    error = getError(test_set, predictions_avg)\n",
    "    print('Error(RMSE): ' + repr(error))\n",
    "    \n",
    "Bagging(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
